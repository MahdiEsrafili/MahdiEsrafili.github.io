<h1 dir = 'rtl'> گرادیان کاهشی </h1>
<p dir = 'rtl'>
در گرادیان کاهشی، هدف اینه که مقدار پارامترهایی که داره یاد گرفته میشه رو با استفاده از مشتق خطا، بروز رسانی بکنیم.<br>
مثلا:
</p>
<pre><code>
model : y = m*x +b
error(MSE) : e = (y-y^)^2
</code></pre>
<p dir = 'rtl'>
این یک مدل رگرسیون خطیه. پارامترهایی که یاد گرفته میشه، شیب خط m و عرض از مبداb هست. پس قراره با بروزرسانی اینها، یادگیری انجام بشه.پس داریم:
</p>
<pre><code>
de/dm = (de/dy^)*(dy^/dm) = -2(y-y^) * (x) = 2x*(y^-y)
de/db = (de/dy^)*(dy^/db) = -2(y-y^) * 1 = 2(y^ - y)
</code></pre>
<p dir = 'rtl'>
  پس ما نرخ رشد خطا نسبت به پارامترهای یادگیری رو پیدا کردیم. پس الان با بروزرسانی اینها در جهت عکس رشد خطا، میتونیم باعث یادگیری مدل بشیم.پس داریم:
 </p>
 <pre><code>
 a = learning rate
 m =m- a*de/dm = m - 2x(y^-y) = m + 2x(y-y^)
 b =b- a*de/db = b - 2(y^-y) = b + 2(y-y^)
 </code></pre>
 <p dir= 'rtl'>
  البته دقت کنید که اگه فرمول محاسبه خطا عوض بشه، اون فرمول بروزرسانی پارامترها هم یه تغییری میکنه. مثلا اگه تبدیل بشه به categorical cross entropy ، دیگه باید مشتق ها رو از نو محاسبه کرد.
  </p>
<pre><code>
categorical cross entropy loss:
e = -sigma(y*y^)
</code></pre>
