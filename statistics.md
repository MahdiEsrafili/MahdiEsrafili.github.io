<h1 dir = 'rtl'> احتمالات </h1>
<h2 dir = 'rtl'>استقلال پیش آمد ها </h2>
<p dir = 'auto'> 
دو پیشامد A, B از هم مستقل هستند اگر :
<br>

P(A∩B) = P(A)P(B)
<br>
مثلا:
</p>
<pre><code>
A={HT,HH} , B={HT,TH} <br>
P(A)=P(B) = 1/4 + 1/4 = 1/2 <br>
P(A∩B) = P({HT}) = 1/4 <br>
P(A)*P(B) = 1/2 * 1/2 = 1/4 <br>
</code></pre>
<h2 dir='rtl'> امید ریاضی</h2>
<p dir = 'rtl'>
یعنی اینکه میانگین چیزی که میبینیم چیه. مثلا بعد از انداختن تاس به تعداد زیاد، میانگین عددی که میبینیم چنده؟<br>
</p>
<pre><code>
E(X) = ∑xP(X=x)<br>
</code></pre>
<p dir= 'rtl'>
مثلا برای تاس ها:
</p>
<pre><code>
E(X) = 1*1/6 + 2*1/6 + 3*1/6 4*1/6 +5*1/6 + 6*1/6 = 3.5
</code></pre>
<p dir= 'rtl'>
این به این معنیه که میانگین عددی که بعد از کلی تاس انداختن میبینیم اینه.<br>
در مسائلی که مقدار پیشامدها عددی نبود(مثل شیر یا خط) ، اونها رو به عدد تبدیل میکنیم.
</p>
<h3 dir = 'rtl'> رابطه امید ریاضی و واریانس</h3>
<p dir = 'rtl'>
واریانس یعنی تفاوت مقدار یک متغیر تصادفی از میانگین یا امید ریاضی اون متغیر:<br>
</p>
<pre><code>
X - E(X)
</code></pre>

<p dir = 'rtl'>
ولی خود همین یه عدد تصادفیه (چون X  تصادفیه) . پس از همین یه امید ریاضی یا میانگین بگیریم:
</p>
<pre><code>
Var(X) = E(X - E(X))
</code></pre>
<p dir ='rtl'>
ولی چون میخوایم واریانس یه عدد مثبت باشه، مقدار داخل امید ریاضی رو به توان دو میرسونیم
</p>
<pre><code>
Var(X) = E((X - E(X))^2)
important:
Var(cX) = c^2Var(X)
Var(X) = E(X^2) - E(X)^2
X , Y independent ⇒ Var(X+Y) = Var(X) + Var(Y)
</code></pre>
<h3 dir = 'rtl'> نامساوی های مهم</h3>
<pre><code>
Markov:
P(X>=a) <= E(X)/a
Chebyschev :
P(|X-EX|>ϵ) <= Var(X)/ ϵ^2
</code></pre>

<h2 dir = 'rtl'> قوانین دمورگان در مجموعه ها </h2>
 <p dir = 'rtl'>
فرض کنیم A , B دو مجموعه در فضای نمونه ها باشند:
 </p>
 <pre><code>
 (A ∪ B)ᶜ = Aᶜ ∩ Bᶜ 
 (A ∩ B)ᶜ = Aᶜ ∪ Bᶜ 
  </code></pre>

<h2 dir ='rtl'> احتمالات شرطی</h2>

<pre><code>
P(A|B) = P(A ∩ B) / P(B)
P(A|B) = P(B|A)*P(A)/P(B)
</code></pre>

<h2 dir ='rtl'> توابع توزیع احتمال </h2>
<p dir = 'rtl'> 
برای اینکه fx  تابع چگالی احتمال درستی باشد:<br>
 </p>
 <pre><code>
 ∫f(x)dx = 1
 </code></pre>
 <h3 dir= 'rtl'> توزیع نرمال</h3>
 <pre><code>
 X ∼ N(μ, σ² )
 pdf :  f(X) = (e^-((x-μ)² ÷ σ²)) / √ (2πσ²) 
 </code></pre>
 <p dir='rtl'>
نکات مهم :<br>
1- اگه X ,Y هر دو توزیع نرمال مستقل از هم باشند، مجموع این دو نیز توزیع نرمال با میانگین مجموع و واریانس مجموع می باشد<br>
2- ضرب عدد ثابت ، میانگین را با همان نسبت و واریانس را با توان دو زیاد می کند.<br>
3- جمع یک عدد ثابت نیز فقط میانگین را همان مقدار زیاد می کند.
 </p>
 <h3 dir = 'rtl'>
 قضیه حد مرکزی
  </h3>

<p dir = 'rtl'>
فرض کنید مجموعه داده ای با میانگین μ  و واریانس  σ²  موجود است. اگر ما از این مجموعه داده N بار نمونه برداری کنیم و میانگین نمونه ها را حساب کنیم، به یک توزیع نرمال با میانگین μ  و واریانس σ²÷N میرسیم. در واقع مهم نیست که توزیع اصلی داده های چی باشه، نرمال باشه یا یکنواخت یا منحرف شده، در نهایت توزیع میانگین نرمال خواهد بود.

</p>

<h2 dir = 'rtl'>
آزمون های آماری Hypothesis Testing
</h2>
<h3 dir ='rtl'> تست مقدار پی  (p-value test) </h3>
<p dir ='rtl'>
در این تست دو تا فرضیه داریم. یکی فرضیه null یا همون H0 که همون اطلاعات قبلیه و چیز جدید بهمون نمیگه. یکی هم فرضیه جایگزین یا آلترناتیو. نحوه تست اینطوری:
<br>
1-فرضیه صفر و آلترناتیو رو مشخص میکنیم<br>
2-مقدار آلفا یا اهمیت رو انتخاب می کنیم<br>
3-فرض میکنیم اگر فرض صفر درست بود، چقدر احتمال داره که تست جدید امکان پذیر باشه. این مقدار احتمال، همون p-value هست.<br>
4-مقدار z رو از جدول یا فرمول بدست می آوریم.<br>
5-اگه مقدار احتمال کمتر از آلفا بود، میگیم که فرض صفر غلطه؛ چون اگه فرض صفر درست بود، نباید میانگین تست جدید در اون بازه می بود.<br>
<br>
این تست یکی از کاربردهای قضیه حد مرکزیه. چون میاد یکی از پارامتر ها که اغلب میانگین هست رو در یه توزیع نرمال بررسی میکنه، که این توزیع احتمال خودش از قضیه حد مرکزی استخراج میشه.
</p>

[یه فیلم خوب برای توضیحش](https://www.youtube.com/watch?v=-FtlH4svqx4)<br>
<p dir ='rtl'>
در واقع اساسش بر اینه که میانگین آزمون جدید چقدر از میانگین فرضیه نال دوره. میدونیم که در توزیع نرمال 68درصد داده ها در فاصله یک واریانس از میانگین، 95 درصد داده ها در فاصله 2 واریانس و 99.7درصد داده ها در فاصله 3 واریانس از میانگین قرار دارد. <br>
میاین با تبدیل z  میسنجیم که میانگین آزمون جدید، چند تا واریانس از میانگین فرض صفر دوره، وقتی اینو بدست آوردیم، میفهمیم که چقدر احتمال داره میانگین جدید در اون فاصله از میانگین اعلام شده قرار داشته باشه. مثلا میفهمیم میانگین جدید به اندازه 3 تا واریانس از میانگین فرض صفر قرار داره، از اون طرف میدونیم 99.7 درصد داده ها در فاصله 3 واریانس از میانگین هستن، پس 0.3 درصد احتمال داره که داده ای، خارج از فاصله 3 واریانس باشه و این 0.3 درصد هم تقسیم میشه (چون توزیع نرمال نسبت به میانگین تقارن داره و نصف میفته پایین تر از میانگین و نصف میفته بالاتر از میانگین).
<br>
پس با توضیحات بالا فهمیدیم این احتمال p یا همون p-value برابر 0.003 هست
<br>
حالا اگه آلفا مون 0.05 باشه، میبینیم که این p-value کمتر از آلفا هست، یعنی کمتر از اون مقدار با اهمیت ما، پس:
<br>
"احتمال نداره که با درست دونستن فرض صفر، میانگین داده های آزمون جدید این مقدار بدست بیاد، پس فرض صفر رده و احتمالا فرض آلترناتیو درست باشه. "<br>
البته نمیشه هم گفت که فرض آلترناتیو درسته، ما فقط فرض صفر رو به نفع فرض آلترناتیو رد میکنیم.
</p>
<pre><code>
centeral limit:
μ = μⁿ 
σⁿ = σ ÷ √n
n = size of test
z transform : z = (μⁿ - μ) ÷ σ 
</code></pre>
<p dir = 'rtl'>
پس اینطوری شد که اول میاین با تبدیل z، میزان فاصله میانگین جدید از میانگین اظهار شده رو نسبت به واریانس میسنجیم، سپس با این عدد میایم از روی جدول z میبینیم چند درصد داده ها داخل و خارج از این فاصله هستن و این احتمال رو با آلفا مقایسه میکنیم و اگر کمتر بود، فرض نال رو رد میکنیم.
</p>